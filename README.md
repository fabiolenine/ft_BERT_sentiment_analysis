# ü§ñ Fine-tuning BERT para An√°lise de Sentimentos

## üìã Vis√£o Geral

Este projeto implementa um pipeline completo de fine-tuning do modelo BERT para classifica√ß√£o de sentimentos em portugu√™s, utilizando o dataset B2W Reviews. O projeto inclui experimenta√ß√£o, versionamento de modelos e estrutura para produ√ß√£o.

## üéØ Caracter√≠sticas Principais

- ‚úÖ **Modelo Base**: `bert-base-portuguese-cased` da Hugging Face
- ‚úÖ **Dataset**: B2W Reviews (132,373 amostras)
- ‚úÖ **GPU Support**: Treinamento otimizado com CUDA
- ‚úÖ **Pr√©-processamento Completo**: Tokeniza√ß√£o, padding, truncamento, m√°scaras de aten√ß√£o
- ‚úÖ **M√©tricas Abrangentes**: Loss, Acur√°cia, Precis√£o, Recall, F1-Score, AUC-ROC
- ‚úÖ **Versionamento de Modelos**: Sistema autom√°tico de compara√ß√£o e promo√ß√£o
- ‚úÖ **Estrutura de Produ√ß√£o**: Diret√≥rios organizados para experimentos e produ√ß√£o


## üèóÔ∏è Estrutura do Projeto

```
ft_BERT_sentiment_analysis/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ bert_sentiment_trainer.py   # Pipeline principal
‚îú‚îÄ‚îÄ notebooks
|   ‚îî‚îÄ‚îÄ BERT_sentiment_trainer.ipynb # Notebook Jupyter: analise, descobertas e treinamento 
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ experiments/                # Modelos experimentais
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ demo_quick/             # Demo executado
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ metadata.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ training_history.png
‚îÇ   ‚îî‚îÄ‚îÄ production/                 # Modelos para produ√ß√£o
‚îú‚îÄ‚îÄ logs/                           # Logs de treinamento
‚îú‚îÄ‚îÄ tests/                          # c√≥digo para teste da API
‚îú‚îÄ‚îÄ api_requirements.txt            # Depend√™ncias do c√≥digo api.py
‚îú‚îÄ‚îÄ requirements.txt                # Depend√™ncias do c√≥digo /src/bert_sentiment_trainer.py
‚îî‚îÄ‚îÄ README.md                       # Documenta√ß√£o
```

## üöÄ Como Usar executar o fine-tuning do BERT para analise de setimentos

### 1. Instala√ß√£o

```bash
pip install -r requirements.txt
```

### 2. Treinamento Completo

```bash
python src/bert_sentiment_trainer.py
```

## üîß Configura√ß√µes

### Hiperpar√¢metros Principais

```python
MAX_LENGTH = 512        # ou 512 para sequ√™ncias mais longas
BATCH_SIZE = 16         # Ajustar conforme GPU dispon√≠vel
EPOCHS = 1              # N√∫mero de √©pocas
LEARNING_RATE = 2e-5    # Taxa de aprendizado
```

### Pr√©-processamento

- **Tokeniza√ß√£o**: BertTokenizer com tokens especiais
- **Padding**: Sequ√™ncias padronizadas para max_length
- **Truncamento**: Textos longos truncados
- **M√°scara de Aten√ß√£o**: Para ignorar tokens de padding
- **Min√∫sculas**: Convers√£o autom√°tica para lowercase

## üìà Versionamento de Modelos

O sistema inclui versionamento autom√°tico:

1. **Experimentos**: Salvos em `models/experiments/`
2. **Promo√ß√£o Autom√°tica**: Modelos melhores promovidos para produ√ß√£o
3. **M√©tricas Rastreadas**: Performance completa salva em metadados
4. **Compara√ß√£o**: F1-Score usado como m√©trica principal

## üîç Avalia√ß√£o

### M√©tricas Implementadas

- **Loss**: Fun√ß√£o de perda durante treinamento
- **Acur√°cia**: Porcentagem de predi√ß√µes corretas
- **Precis√£o**: Precis√£o por classe (weighted average)
- **Recall**: Recall por classe (weighted average)
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall
- **AUC-ROC**: √Årea sob a curva ROC

### Exemplo de Predi√ß√µes

```python
# Exemplos testados no demo
texts = [
    "Este produto √© excelente! Recomendo muito.",     # ‚Üí Positivo (95%)
    "Produto horr√≠vel, n√£o funciona. N√£o comprem.",  # ‚Üí Negativo (67%)
    "Produto ok, nada especial mas funciona."        # ‚Üí Positivo (80%)
]
```

## üõ†Ô∏è Classes Principais

### `BERTSentimentTrainer`
- Gerencia o treinamento do modelo BERT
- Implementa avalia√ß√£o com m√©tricas completas
- Suporte a GPU autom√°tico

### `SentimentDataset`
- Dataset customizado para PyTorch
- Pr√©-processamento integrado
- Compat√≠vel com DataLoader

### `ModelVersionManager`
- Versionamento autom√°tico de modelos
- Compara√ß√£o de performance
- Promo√ß√£o para produ√ß√£o

## üìù Logs e Monitoramento

### Sistema de Logging Profissional do Treinamento

O projeto inclui um sistema de logging completo e estruturado para o treinamento:

#### üîß **Configura√ß√£o de Logging**
- **Formato estruturado**: timestamp, nome, n√≠vel e mensagem detalhada
- **M√∫ltiplos handlers**: console + arquivo increment√°vel (`logs/train/bert_sentiment_training.log`)
- **Logging incremental**: Preserva hist√≥rico de todas as execu√ß√µes
- **Encoding UTF-8** para caracteres especiais
- **N√≠veis apropriados**: INFO, WARNING, ERROR, DEBUG

#### üìä **Rastreamento Detalhado**
- **Inicializa√ß√£o do modelo**: Carregamento, configura√ß√µes e par√¢metros
- **Processamento de dados**: Carregamento, distribui√ß√£o de classes, splits
- **Treinamento**: Progresso por √©poca, loss, m√©tricas, detec√ß√£o de overfitting
- **Avalia√ß√£o**: M√©tricas completas, timing de predi√ß√µes
- **Gerenciamento de modelos**: Salvamento, promo√ß√£o, versionamento

#### üéØ **Monitoramento de Performance**
- **Timing completo**: Dura√ß√£o de cada fase do pipeline
- **M√©tricas em tempo real**: Loss, acur√°cia, F1-score por √©poca
- **Alertas autom√°ticos**: Detec√ß√£o de overfitting e performance baixa
- **Benchmarks**: Classifica√ß√£o autom√°tica de performance (Excelente/Bom/Razo√°vel/Baixo)

#### üìà **Exemplo de Logs de Treinamento**

```
2025-07-15 10:30:15,123 - __main__ - INFO - === NOVA SESS√ÉO DE TREINAMENTO INICIADA ===
2025-07-15 10:30:15,124 - __main__ - INFO - Log sendo salvo em: /path/to/logs/train/bert_sentiment_training.log
2025-07-15 10:30:15,125 - __main__ - INFO - Inicializando BERTSentimentTrainer com modelo: neuralmind/bert-base-portuguese-cased
2025-07-15 10:30:17,456 - __main__ - INFO - N√∫mero de par√¢metros do modelo: 110,052,098
2025-07-15 10:30:20,123 - __main__ - INFO - Carregando dataset: ruanchaves/b2w-reviews01
2025-07-15 10:30:25,789 - __main__ - INFO - Total de amostras: 132,373
2025-07-15 10:30:25,790 - __main__ - INFO - Distribui√ß√£o de classes: {0: 52,437, 1: 79,936}
2025-07-15 10:30:30,123 - __main__ - INFO - === INICIANDO TREINAMENTO ===
2025-07-15 10:30:30,124 - __main__ - INFO - √âpocas: 3, Batch size: 16, Learning rate: 2e-05
2025-07-15 10:35:45,234 - __main__ - INFO - √âpoca 1/3 conclu√≠da: Loss m√©dio: 0.3245, Acur√°cia: 0.8567
2025-07-15 10:35:50,345 - __main__ - INFO - Valida√ß√£o √©poca 1: F1-Score: 0.8501, AUC-ROC: 0.8876
2025-07-15 10:45:20,567 - __main__ - INFO - ‚úÖ EXCELENTE: F1-Score >= 0.8
2025-07-15 10:45:25,678 - __main__ - INFO - Dura√ß√£o total do pipeline: 0:15:10.555
2025-07-15 10:45:25,679 - __main__ - INFO - ‚úÖ Pipeline de fine-tuning BERT conclu√≠do com sucesso!
```

#### üöÄ **Benef√≠cios do Sistema de Logging**
- **Debugging eficiente**: Contexto completo para identificar problemas
- **Monitoramento de performance**: Tracking detalhado de cada fase
- **Auditoria completa**: Hist√≥rico permanente de todas as execu√ß√µes
- **Troubleshooting**: Stack traces e informa√ß√µes detalhadas para erros
- **M√©tricas de produ√ß√£o**: Dados para an√°lise de desempenho e otimiza√ß√£o

- Hist√≥rico de treinamento salvo automaticamente
- Gr√°ficos de loss e acur√°cia gerados
- Metadados completos para cada experimento
- Timestamps para rastreabilidade

## üåê API REST

O projeto inclui uma API REST completa e profissional para servir o modelo em produ√ß√£o:

### üìÅ Arquivos da API

1. **api.py** - API principal com:
   - Endpoint POST `/predict` que aceita JSON com campo "text"
   - Retorna sentimento ("positivo"/"negativo") e score de confian√ßa
   - Carregamento autom√°tico do modelo BERT treinado
   - Tratamento robusto de erros para requests malformados
   - Endpoints adicionais: `/health` e `/`
   - **Sistema de logging profissional**

2. **api_requirements.txt** - Depend√™ncias necess√°rias para a API

3. **test_api.py** - Script de testes abrangentes

### üöÄ Para usar a API:

```bash
# Instalar depend√™ncias
pip install -r api_requirements.txt

# Executar a API
python api.py
```

A API estar√° dispon√≠vel em `http://localhost:8000` com documenta√ß√£o Swagger em `/docs`.

### üìÑ Documenta√ß√£o da API

A documenta√ß√£o interativa da API est√° dispon√≠vel em:
- **Swagger UI**: `http://localhost:8000/docs`

Estas interfaces permitem testar os endpoints diretamente no navegador e explorar a especifica√ß√£o OpenAPI completa.

![Documenta√ß√£o da API - Wragger UI](imgs/api_wragger_ui.png)


### üìä Sistema de Logging Profissional

A API inclui um sistema de logging completo e estruturado:

#### üîß **Configura√ß√£o de Logging**
- **Formato estruturado**: timestamp, nome, n√≠vel, fun√ß√£o, linha e mensagem
- **M√∫ltiplos handlers**: console + arquivo (`api.log`)
- **Encoding UTF-8** para caracteres especiais
- **N√≠veis apropriados**: INFO, WARNING, ERROR, DEBUG

#### üìà **Rastreamento de Requests**
- **Request ID √∫nico** para cada solicita√ß√£o (UUID)
- **Middleware de logging** que captura todas as requisi√ß√µes
- **Timing de requests** com medi√ß√£o de performance
- **IP do cliente** para auditoria e monitoramento
- **Logs de entrada e sa√≠da** para cada endpoint

#### üéØ **Logs Detalhados de Predi√ß√µes**
- **Preview do texto** (primeiros 50 caracteres)
- **Tamanho do texto** em caracteres
- **Tempo de processamento** de cada predi√ß√£o
- **Resultados completos** (sentimento, score, timing)
- **Rastreamento por Request ID**

#### ‚ö†Ô∏è **Tratamento de Erros Robusto**
- **Contexto completo**: request ID, client IP, erro espec√≠fico
- **Stack traces completos** para erros inesperados
- **Logs de valida√ß√£o** para entradas inv√°lidas
- **Separa√ß√£o por severidade** (warning vs error)

#### üöÄ **Startup e Monitoramento**
- **Informa√ß√µes do sistema** (vers√µes PyTorch, CUDA dispon√≠vel)
- **Tempo de inicializa√ß√£o** do modelo
- **Health checks detalhados** com status do modelo
- **Logs de shutdown** para encerramento gracioso

#### üìù **Exemplo de Logs**

```
2025-07-14 10:30:15,123 - __main__ - INFO - [startup_event:137] - === Iniciando API BERT Sentiment Analysis ===
2025-07-14 10:30:15,124 - __main__ - INFO - [startup_event:139] - PyTorch version: 2.0.1
2025-07-14 10:30:15,125 - __main__ - INFO - [startup_event:141] - CUDA dispon√≠vel: True
2025-07-14 10:30:17,456 - __main__ - INFO - [load_model:66] - Modelo carregado com sucesso em 2.33s - Device: cuda
2025-07-14 10:30:20,123 - __main__ - INFO - [log_requests:124] - Incoming request - ID: a1b2c3d4 - Method: POST - URL: http://localhost:8000/predict - Client: 127.0.0.1
2025-07-14 10:30:20,124 - __main__ - INFO - [predict_sentiment:164] - Nova solicita√ß√£o de predi√ß√£o - Request: a1b2c3d4 - Client: 127.0.0.1
2025-07-14 10:30:20,125 - __main__ - INFO - [predict:82] - Iniciando predi√ß√£o - Request: a1b2c3d4 - Texto: 'Eu adorei o produto, a entrega foi muito r√°pida!' - Tamanho: 47 chars
2025-07-14 10:30:20,234 - __main__ - INFO - [predict:104] - Predi√ß√£o conclu√≠da - Request: a1b2c3d4 - Resultado: positivo - Score: 0.9876 - Tempo: 0.109s
2025-07-14 10:30:20,235 - __main__ - INFO - [predict_sentiment:180] - Predi√ß√£o entregue com sucesso - Request: a1b2c3d4 - Client: 127.0.0.1
2025-07-14 10:30:20,236 - __main__ - INFO - [log_requests:129] - Request completed - ID: a1b2c3d4 - Status: 200 - Time: 0.113s
```

### üîç **Benef√≠cios do Sistema de Logging**

- **Debugging eficiente**: Request IDs √∫nicos para rastrear problemas
- **Monitoramento de performance**: Timing detalhado de cada opera√ß√£o
- **Auditoria completa**: IP do cliente e hist√≥rico de todas as requests
- **Troubleshooting**: Stack traces e contexto completo para erros
- **M√©tricas de produ√ß√£o**: Dados para an√°lise de uso e performance

## üéØ Pr√≥ximos Passos

Para expandir o projeto:

1. **Hyperparameter Tuning**: Usar Optuna ou similar
2. **Cross-Validation**: Implementar valida√ß√£o cruzada
3. **Ensemble Models**: Combinar m√∫ltiplos modelos
4. **Monitoramento**: MLflow ou Weights & Biases
5. **CI/CD**: Pipeline automatizado
6. **Versionamento**: Melhorar o versionamento dos modelos utilizando os servi√ßos de nuvem cloud
7. **Balancemanto**: Disponibilizar o servi√ßco de API com balancemaneto e escalonamento autom√°tico 

## üìã Requisitos

- Python 3.9+
- CUDA (opcional, mas recomendado)
- 8GB+ RAM
- ~2GB espa√ßo em disco

## üèÜ Performance

O modelo demonstrou excelente performance:
- Converg√™ncia r√°pida (1 √©poca)
- Alta acur√°cia (85.5%)
- Bom balanceamento precis√£o/recall
- AUC-ROC superior a 88%

---

**Desenvolvido com PyTorch e Transformers** üöÄ